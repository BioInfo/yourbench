task_name: test_simple_dataset
datasets:
  document_dataset_name: sumuks/fairytales
  # if both the names are the same, we'll attempt to push back to the original dataset
  document_with_summary_dataset_name: sumuks/fairytales
  chunked_doucments_dataset_name: sumuks/fairytales_semantically_chunked
chunking_configuration:
  model_name: sentence-transformers/all-MiniLM-L6-v2
  min_tokens: 512 # tokens
  target_chunk_size: 1024 # tokens
  max_tokens: 2048 # tokens
  similarity_threshold: 0.7
  device: cuda # if you have a GPU, you can use it here or set to cpu
pipeline_config:
  # - generate_summaries
  - create_chunks
prompt_prefix: general
model_config:
  # models are prioritized by the order they are defined in the config
  summarization_model:
    model_name: gpt-4o
    model_type: azure
    # model_name: claude-3-5-sonnet-20241022
    # model_name: claude-3-haiku-20240307
    # model_type: anthropic

  model_0:
    model_name:  