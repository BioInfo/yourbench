task_name: test_simple_dataset
datasets:
  document_dataset_name: sumuks/fairytales
  # if both the names are the same, we'll attempt to push back to the original dataset
  document_with_summary_dataset_name: sumuks/fairytales
  chunked_doucments_dataset_name: sumuks/fairytales_semantically_chunked
  single_shot_questions_dataset_name: sumuks/fairytales_single_shot_questions_llama3_3_70b
chunking_configuration:
  model_name: sentence-transformers/all-MiniLM-L6-v2
  min_tokens: 256 # tokens
  target_chunk_size: 512 # tokens
  max_tokens: 1024 # tokens
  similarity_threshold: 0.3
  device: cuda # if you have a GPU, you can use it here or set to cpu
question_generation_config:
  prompt_prefix: simple_qg
  test_audience: "5th grader, with longer attention span, and longer answers"
  # test_audience: "phd"
pipeline_config:
  - generate_dataset
  # - generate_summaries
  # - create_chunks
  # - make_multihop_chunks
  # - create_single_shot_questions
prompt_prefix: general
model_config:
  # models are prioritized by the order they are defined in the config
  summarization_model:
    model_name: gpt-4o
    model_type: azure
    # model_name: claude-3-5-sonnet-20241022
    # model_name: claude-3-haiku-20240307
    # model_type: anthropic

  model_0:
    model_name: meta-llama/Meta-Llama-3.3-70B-Instruct
    model_type: openai
    base_url: http://localhost:30000/v1/
    api_key: "EMPTY"
  model_1:
    model_name: gpt-4o-mini
    model_type: azure
  model_2:
    model_name: meta-llama/llama-3.3-70b-instruct
    model_type: openai
    base_url: https://openrouter.ai/api/v1
    api_key: "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"
