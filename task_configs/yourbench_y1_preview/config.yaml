# the task name is to be used to identify the task in the logs and output files. you must use a unique name for each task, and pass it as an argument to the yourbench command.
task_name: yourbench_y1_preview

# these are special, pipeline wide configurations you can make
configurations:
  # huggingface specific configurations
  huggingface:
    push_to_huggingface: true # this determines whether the dataset is pushed to huggingface after generation
    hf_organization: sumuks # this is the organization to push the dataset to, if push_to_huggingface is true
    set_hf_repo_visibility: private # this determines the visibility of the huggingface repo.
    concat_if_exists: false # this determines whether to concatenate the dataset if it already exists.

  # model specific configurations
  # base urls and api keys will be loaded from the environment variables
  model:
    # here is an example of how to use azure openai's gpt-4o-mini model
    model_name: gpt-4o-mini # your model identifier.
    model_type: azure # this is the type of model you are using. refer to https://docs.litellm.ai/docs/providers for more information.
    max_concurrent_requests: 8 # this is the maximum number of concurrent requests to the model.
  
# these are where you decide which parts of the pipeline to activate and execute
# to execute each pipeline part, you must set execute to true explicitly
pipeline:
  generate_dataset:
    execute: true
    # this is where the source documents are located
    files_directory: examples/yourbench_y1_preview/
    dataset_name: yourbench_y1_preview
