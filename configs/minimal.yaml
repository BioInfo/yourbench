# minimal example

hf_configuration:
  token: $HF_TOKEN 
  hf_organization: $HF_ORGANIZATION 
  private: false 
  global_dataset_name: sumuks/yourbench-example

# === MODEL CONFIGURATION ===
model_list: 
  # to use openai inference
  - model_name: gpt-4o-mini
    
model_roles:
  ingestion:
    - gpt-4o-mini

pipeline:
  ingestion:
    run: true
    source_documents_dir: data/example/raw
    output_dir: data/example/processed
  upload_ingest_to_hub:
    run: true
    source_documents_dir: data/example/processed
  summarization:
    run: true
  chunking:
    run: true
  single_shot_question_generation:
    run: true
  multi_hop_question_generation:
    run: true
  lighteval:
    run: true
  
  
